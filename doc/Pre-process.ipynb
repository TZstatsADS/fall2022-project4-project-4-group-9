{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1CVNJscdczMHaIFg2J45K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":47,"metadata":{"id":"cT1CXtK9iS9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669328723933,"user_tz":300,"elapsed":156,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"8232afd5-eb69-4d2a-b386-5b68a8032e67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex',\n","       'dob', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n","       'juv_misd_count', 'juv_other_count', 'priors_count',\n","       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out',\n","       'c_case_number', 'c_offense_date', 'c_arrest_date',\n","       'c_days_from_compas', 'c_charge_degree', 'c_charge_desc',\n","       'is_recid', 'r_case_number', 'r_charge_degree',\n","       'r_days_from_arrest', 'r_offense_date', 'r_charge_desc',\n","       'r_jail_in', 'r_jail_out', 'violent_recid', 'is_violent_recid',\n","       'vr_case_number', 'vr_charge_degree', 'vr_offense_date',\n","       'vr_charge_desc', 'type_of_assessment', 'decile_score.1',\n","       'score_text', 'screening_date', 'v_type_of_assessment',\n","       'v_decile_score', 'v_score_text', 'v_screening_date', 'in_custody',\n","       'out_custody', 'priors_count.1', 'start', 'end', 'event',\n","       'two_year_recid'], dtype=object)"]},"metadata":{},"execution_count":47}],"source":["import pandas as pd\n","df = pd.read_csv(\"compas-scores-two-years.csv\")\n","df = df.loc[df[\"race\"].isin([\"African-American\", \"Caucasian\"])]\n","df[\"race\"].replace(['African-American', 'Caucasian'],[0, 1], inplace=True)\n","df[\"sex\"] = pd.get_dummies(df[\"sex\"])[\"Female\"]\n","le={\"Low\":0,\"Medium\":1,\"High\":2}\n","df[\"score_text\"]= df[\"score_text\"].replace(le)\n","df.columns.values"]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jctF7al2pogs","executionInfo":{"status":"ok","timestamp":1669327132431,"user_tz":300,"elapsed":143,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"b444fa10-99c3-49e3-a043-0e0ee124e1f1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6150"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["s = df[\"race\"]\n","y = df[\"two_year_recid\"]\n","X = pd.DataFrame(df, columns=[\"race\",\"age\",\"priors_count\",\"juv_fel_count\",\"juv_misd_count\",\"juv_other_count\",'decile_score','score_text',\"sex\"])"],"metadata":{"id":"ndHZthWlirHq","executionInfo":{"status":"ok","timestamp":1669329179388,"user_tz":300,"elapsed":3,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=879, random_state=42, stratify=y)\n","(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8e3twohkoNa","executionInfo":{"status":"ok","timestamp":1669329182224,"user_tz":300,"elapsed":5,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"d3c99a5d-c7d6-4e2c-9bef-664f78b8b14c"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(((5271, 9), (5271,)), ((879, 9), (879,)))"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["X_train, X_valid, y_train, y_valid=train_test_split(X_train,y_train,test_size=879, random_state=42, stratify=y_train)\n","(X_train.shape, y_train.shape), (X_valid.shape, y_valid.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FliTJHLuqAm6","executionInfo":{"status":"ok","timestamp":1669329183761,"user_tz":300,"elapsed":4,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"dde554c6-76a7-439f-c685-5855ca9a5957"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(((4392, 9), (4392,)), ((879, 9), (879,)))"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","source":["#Baseline"],"metadata":{"id":"jsHi_CVIwW3-"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","clf = LogisticRegression(random_state=0).fit(X_train, y_train)"],"metadata":{"id":"O5PwLhXlqomt","executionInfo":{"status":"ok","timestamp":1669329186507,"user_tz":300,"elapsed":161,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["clf.score(X_test,y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLIDSOmEvykI","executionInfo":{"status":"ok","timestamp":1669329188132,"user_tz":300,"elapsed":157,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"9d20b9ce-ad2a-482c-e302-c37ba57d099d"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7007963594994312"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","y_pred=clf.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRzlhM2Aw8Q9","executionInfo":{"status":"ok","timestamp":1669329559479,"user_tz":300,"elapsed":5,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"b24f98b7-e995-4ce2-ecc3-fc6af6beddce"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.70      0.78      0.74       469\n","           1       0.71      0.61      0.65       410\n","\n","    accuracy                           0.70       879\n","   macro avg       0.70      0.69      0.70       879\n","weighted avg       0.70      0.70      0.70       879\n","\n"]}]},{"cell_type":"code","source":["#calibration score\n","from sklearn import metrics\n","abs(metrics.recall_score(y_test, y_pred, pos_label=0)-metrics.recall_score(y_test, y_pred, pos_label=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqKXo1eG1b3Y","executionInfo":{"status":"ok","timestamp":1669330317996,"user_tz":300,"elapsed":5,"user":{"displayName":"Donglai Xu","userId":"08010117615012465327"}},"outputId":"485dbc0d-2576-416e-ebf4-5ccf6bcec4b2"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.17519891830048362"]},"metadata":{},"execution_count":84}]}]}